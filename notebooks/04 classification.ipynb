{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "Training a classification model for marketplace images using transfer learning:\n",
    "\n",
    "- Frozen Backbone: Uses a pre-trained DINOv2 (Vision Transformer) as feature extractor\n",
    "- Classification Head: Trains a linear or MLP classification head on top of DINOv2 embeddings\n",
    "- MLflow Tracking: Logs all training metrics, hyperparameters, and model checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "notebooks_dir = Path().absolute()\n",
    "project_dir = notebooks_dir.parent\n",
    "os.chdir(project_dir)\n",
    "load_dotenv()\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "from dataset.dataset import MarketplaceDataModule\n",
    "from dataset.model import DinoV2Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"xFormers is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(dataset, method=\"inverse_sqrt\"):\n",
    "    \"\"\"\n",
    "    Compute class weights for handling imbalanced datasets.\n",
    "\n",
    "    Args:\n",
    "        dataset: ImageFolder dataset or DataModule with .targets attribute\n",
    "        method: Weighting method\n",
    "            - \"inverse\": weight = 1 / count (strong reweighting)\n",
    "            - \"inverse_sqrt\": weight = 1 / sqrt(count) (moderate, recommended)\n",
    "            - \"effective\": Effective number of samples (Cui et al. 2019)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor of shape (num_classes,) with normalized weights\n",
    "    \"\"\"\n",
    "    # Get class counts\n",
    "    targets = np.array(dataset.targets)\n",
    "    unique_classes, counts = np.unique(targets, return_counts=True)\n",
    "    num_classes = len(unique_classes)\n",
    "\n",
    "    # Compute weights based on method\n",
    "    if method == \"inverse\":\n",
    "        weights = 1.0 / counts\n",
    "    elif method == \"inverse_sqrt\":\n",
    "        weights = 1.0 / np.sqrt(counts)\n",
    "    elif method == \"effective\":\n",
    "        # Effective number: (1 - beta^n) / (1 - beta)\n",
    "        beta = 0.9999\n",
    "        effective_num = 1.0 - np.power(beta, counts)\n",
    "        weights = (1.0 - beta) / effective_num\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    # Normalize weights to sum to num_classes (keeps loss scale similar)\n",
    "    weights = weights / weights.sum() * num_classes\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 223\n",
      "\n",
      "Weight statistics (inverse_sqrt method):\n",
      "  Min weight: 0.5344\n",
      "  Max weight: 3.0320\n",
      "  Mean weight: 1.0000\n",
      "  Std weight: 0.7026\n",
      "\n",
      "Sample class weights (inverse_sqrt):\n",
      "  adults handicrafts: 949 samples ‚Üí weight=0.5480\n",
      "  adults health beauty: 956 samples ‚Üí weight=0.5460\n",
      "  adults homeware: 916 samples ‚Üí weight=0.5578\n",
      "  adults misc: 961 samples ‚Üí weight=0.5446\n",
      "  animals: 970 samples ‚Üí weight=0.5420\n"
     ]
    }
   ],
   "source": [
    "# Example: Compute and inspect class weights\n",
    "data_module_temp = MarketplaceDataModule(batch_size=64)\n",
    "data_module_temp.setup(\"fit\")\n",
    "\n",
    "# Get the full dataset to compute weights\n",
    "full_dataset = data_module_temp.train_dataset.dataset\n",
    "\n",
    "# Compute weights using different methods\n",
    "weights_inv = compute_class_weights(full_dataset, method=\"inverse\")\n",
    "weights_sqrt = compute_class_weights(full_dataset, method=\"inverse_sqrt\")\n",
    "\n",
    "print(f\"Number of classes: {len(full_dataset.classes)}\")\n",
    "print(f\"\\nWeight statistics ({'inverse_sqrt'} method):\")\n",
    "print(f\"  Min weight: {weights_sqrt.min():.4f}\")\n",
    "print(f\"  Max weight: {weights_sqrt.max():.4f}\")\n",
    "print(f\"  Mean weight: {weights_sqrt.mean():.4f}\")\n",
    "print(f\"  Std weight: {weights_sqrt.std():.4f}\")\n",
    "\n",
    "# Show weights for a few classes\n",
    "print(f\"\\nSample class weights ({'inverse_sqrt'}):\")\n",
    "targets = np.array(full_dataset.targets)\n",
    "for i in range(min(5, len(full_dataset.classes))):\n",
    "    class_name = full_dataset.classes[i]\n",
    "    count = (targets == i).sum()\n",
    "    weight = weights_sqrt[i].item()\n",
    "    print(f\"  {class_name}: {count} samples ‚Üí weight={weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://192.168.30.108:5000/\n",
      "‚úì Successfully connected to MLflow!\n",
      "üèÉ View run luminous-lark-134 at: http://192.168.30.108:5000/#/experiments/2/runs/6be4554a4e58446fab11fe136c553286\n",
      "üß™ View experiment at: http://192.168.30.108:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "with mlflow.start_run():\n",
    "    print(\"‚úì Successfully connected to MLflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model: pl.LightningModule,\n",
    "    data_module: pl.LightningDataModule,\n",
    "    max_epochs: int,\n",
    "    precision: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Configures and runs a Lightning training process.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize trainer\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=\"marketplace-image-rag\", \n",
    "        # tracking_uri=\"file:./ml-runs\"\n",
    "    )\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5,\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=3,\n",
    "        dirpath=\"checkpoints\",\n",
    "        filename=\"dinov2-classification-{epoch:02d}-{val_accuracy:.4f}\",\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,  # maximum number of training epochs\n",
    "        precision=precision,  # numerical precision for the training process\n",
    "        logger=mlf_logger,  # logging training metrics to mlflow\n",
    "        enable_progress_bar=True,  # show training progress\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "    )\n",
    "\n",
    "    # start the training process\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------\n",
      "0 | model        | Sequential         | 86.8 M | train | 0    \n",
      "1 | loss_fn      | CrossEntropyLoss   | 0      | train | 0    \n",
      "2 | val_accuracy | MulticlassAccuracy | 0      | train | 0    \n",
      "--------------------------------------------------------------------\n",
      "171 K     Trainable params\n",
      "86.6 M    Non-trainable params\n",
      "86.8 M    Total params\n",
      "347.020   Total estimated model params size (MB)\n",
      "204       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1519/1519 [08:07<00:00 [00:10<08:38,  3.12it/s, v_num=6330, val_loss=1.340, val_accuracy=0.679]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run crawling-grub-159 at: http://192.168.30.108:5000/#/experiments/2/runs/6e10f2dae99c4f88ae8782159af66330\n",
      "üß™ View experiment at: http://192.168.30.108:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# train classification head on tensor cores (speedup) \n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "data_module = MarketplaceDataModule(batch_size=64)\n",
    "data_module.setup(\"fit\")\n",
    "num_classes = len(data_module.train_dataset.dataset.classes)\n",
    "class_weights = compute_class_weights(data_module.full_dataset, method=\"inverse_sqrt\")\n",
    "\n",
    "model = DinoV2Classification(\n",
    "    num_classes=num_classes,\n",
    "    class_weights=class_weights.tolist(),\n",
    ")\n",
    "\n",
    "# Execute the training\n",
    "trainer = run_training(\n",
    "    model=model,\n",
    "    data_module=data_module,\n",
    "    max_epochs=5,\n",
    "    # evaluate backbone on tensor cores (speedup)\n",
    "    precision=\"16-mixed\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marketplace-image-rag (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
